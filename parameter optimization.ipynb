{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 网格搜索寻优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "def find_best_params_GridSearchCV(model, param_grid, X, y, cv=5, scoring='accuracy'):\n",
    "    \"\"\"\n",
    "    使用GridSearchCV寻找模型的最佳参数\n",
    "\n",
    "    参数:\n",
    "    model: 待优化的模型实例,必须是sklearn.BaseEstimator的子类\n",
    "    param_grid: 参数网格，字典格式，键是参数名，值是参数取值列表,参数格式如下\n",
    "        # param_grid = {'C': [0.1, 1, 10], 'gamma': ['scale', 'auto'], 'kernel': ['rbf', 'linear']}\n",
    "    X: 训练数据特征,二维数组或DataFrame\n",
    "    y: 训练数据标签,一维数组或Series\n",
    "    cv: 可选,默认为5,交叉验证的折数\n",
    "    scoring: 可选，默认为'accuracy'，评估指标\n",
    "\n",
    "    返回:\n",
    "    grid: GridSearchCV对象,包含最佳参数和最佳得分等信息\n",
    "\n",
    "    抛出:\n",
    "    TypeError: 如果输入参数的类型不正确\n",
    "    Exception: 如果在模型训练过程中发生错误\n",
    "    \"\"\"\n",
    "\n",
    "# 1. `estimator`：要优化的 estimator 对象，即模型对象。\n",
    "# 2. `param_grid`：一个字典，用于指定要搜索的超参数及其可能的值。\n",
    "#     例如，`param_grid = {'C': [0.1, 1, 10], 'gamma': [0.1, 1]}` 表示要搜索的两个超参数 `C` 和 `gamma`，\n",
    "#     它们的值分别为 0.1、1 和 10。\n",
    "# 3. `scoring`：一个字符串或一个 scoring 对象，用于指定评估模型性能的指标。例如，`scoring = 'accuracy'` \n",
    "#     表示使用准确率作为评估指标。\n",
    "# 4. `cv`：一个整数或一个 cross-validation 策略对象，用于指定交叉验证的策略。例如，`cv = 5` 表示使用 5 折交叉验证。\n",
    "# 5. `n_jobs`：一个整数，用于指定并行计算的工作进程数。例如，`n_jobs = -1` 表示使用所有的 CPU 核心进行并行计算。\n",
    "# 6. `verbose`：一个整数，用于指定日志的详细程度。例如，`verbose = 2` 表示输出更多的日志信息。\n",
    "# 7. `pre_dispatch`：一个字符串或一个整数，用于指定预分配给每个工作进程的计算资源。\n",
    "#     例如，`pre_dispatch = '2*n_jobs'` 表示每个工作进程将获得 2 倍的计算资源。\n",
    "# 8. `random_state`：一个整数，用于指定随机数种子。\n",
    "\n",
    "    # 检查输入数据类型和大小\n",
    "    X, y = check_X_y(X, y)\n",
    "    \n",
    "    # 检查模型是否为BaseEstimator的子类,检查param_grid是否为字典\n",
    "    if not isinstance(model, BaseEstimator):\n",
    "        raise TypeError('model must be an instance of sklearn.BaseEstimator')\n",
    "\n",
    "    if not isinstance(param_grid, dict):\n",
    "        raise TypeError('param_grid must be a dictionary')\n",
    "\n",
    "    # 创建并训练GridSearchCV对象\n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=cv, scoring=scoring, n_jobs=-1)\n",
    "    \n",
    "    try:\n",
    "        grid_search.fit(X, y)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An error occurred during fitting: {e}\")\n",
    "\n",
    "    # 确保模型已成功训练\n",
    "    check_is_fitted(grid_search, 'best_estimator_')\n",
    "\n",
    "    # print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    # print(f\"Best score: {grid_search.best_score_}\")\n",
    "    \n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 随机搜索寻优"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机寻优可以使用网格参数，但是这样会失去随机寻优的优势。随机寻优的核心在于它不是穷举所有可能的参数组合，而是从参数空间中随机选择组合进行尝试。\n",
    "这种方法在参数空间较大时更加高效，因为它不会测试所有组合，而是通过随机采样来探索参数空间。\n",
    "如果你在随机寻优中使用网格参数，即指定参数的固定值而不是分布，那么你实际上是在进行一种特殊的随机寻优，它可能会更接近于网格寻优的行为。\n",
    "这样做不会充分利用随机寻优的灵活性，因为你没有指定参数的分布，而是给出了一个固定的值列表。\n",
    "例如，如果你在随机寻优中设置了参数如下：\n",
    "```python\n",
    "param_dist = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    # ... 其他参数 ...\n",
    "}\n",
    "```\n",
    "在这种情况下，`n_estimators` 和 `max_depth` 的可能取值是固定的，而不是随机的。每次迭代时，`RandomizedSearchCV` 将从这些固定的值中随机选择，而不是从可能的分布中采样。这可能会导致搜索过程更接近于网格寻优，因为你实际上是在一个有限的网格上随机选择点。\n",
    "如果你想充分利用随机寻优的优势，你应该为每个参数定义一个分布，例如：\n",
    "```python\n",
    "param_dist = {\n",
    "    'n_estimators': randint(10, 200),  # 从10到200的整数\n",
    "    'max_depth': randint(1, 30),       # 从1到30的整数，包括None\n",
    "    # ... 其他参数 ...\n",
    "}\n",
    "```\n",
    "在这个例子中，`randint` 分布将允许 `n_estimators` 从10到200的整数中随机选择，而 `max_depth` 可以从1到30的整数中随机选择，包括 `None`。这样，每次迭代都会从这些分布中随机采样参数值，从而更有效地探索参数空间。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.utils.validation import check_X_y, check_is_fitted\n",
    "\n",
    "def find_best_params_RandomizedSearchCV(model, param_grid, X, y, cv=5, scoring='accuracy', n_iter=10):\n",
    "    \"\"\"\n",
    "    使用RandomizedSearchCV寻找模型的最佳参数\n",
    "\n",
    "    参数:\n",
    "    model: 待优化的模型实例,必须是sklearn.BaseEstimator的子类\n",
    "    param_grid: 参数空间，字典格式，键是参数名，值是参数取值分布,参数格式如下\n",
    "        # from scipy.stats import randint, uniform\n",
    "        # param_dist = {\n",
    "        #'n_estimators': randint(50, 200),  # 从50到200的整数\n",
    "        #'max_depth': randint(2, 10),       # 从2到10的整数\n",
    "        #'min_samples_split': randint(2, 11),  # 从2到10的整数\n",
    "        #'min_samples_leaf': randint(1, 11),   # 从1到10的整数\n",
    "        #'max_features': uniform(0, 1),        # 从0到1的均匀分布\n",
    "        # }\n",
    "\n",
    "    X: 训练数据特征,二维数组或DataFrame\n",
    "    y: 训练数据标签,一维数组或Series\n",
    "    cv: 可选,默认为5,交叉验证的折数\n",
    "    scoring: 可选，默认为'accuracy'，评估指标\n",
    "    n_iter: 可选,默认为10,随机搜索的迭代次数\n",
    "\n",
    "    返回:\n",
    "    random_search: RandomizedSearchCV对象,包含最佳参数和最佳得分等信息\n",
    "\n",
    "    抛出:\n",
    "    TypeError: 如果输入参数的类型不正确\n",
    "    Exception: 如果在模型训练过程中发生错误\n",
    "    \"\"\"\n",
    "    \n",
    "    # 检查输入数据类型和大小\n",
    "    X, y = check_X_y(X, y)\n",
    "    # 检查模型是否为BaseEstimator的子类,检查param_grid是否为字典\n",
    "    if not isinstance(model, BaseEstimator):\n",
    "        raise TypeError('model must be an instance of sklearn.BaseEstimator')\n",
    "        \n",
    "    # 检查param_grid是否为字典\n",
    "    if not isinstance(param_grid, dict):\n",
    "        raise TypeError('param_grid must be a dictionary')\n",
    "\n",
    "    random_search = RandomizedSearchCV(\n",
    "        estimator=model,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=n_iter,\n",
    "        cv=cv,\n",
    "        scoring=scoring\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        random_search.fit(X, y)\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An error occurred during fitting: {e}\")\n",
    "\n",
    "    # 确保模型已成功训练\n",
    "    check_is_fitted(random_search, 'best_estimator_')\n",
    "    return random_search"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
